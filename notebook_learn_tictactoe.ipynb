{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL agent Q-learning for TicTacToe env\n",
    "\n",
    "The [Tic-Tac-Toe](https://github.com/MauroLuzzatto/OpenAI-Gym-TicTacToe-Environment) is a simple game environment that allows to train reinforcement learning agents. These notebook contains an implemetation of Q-learning with epsilon-greedy strategy for TicTacToe env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the python modules\n",
    "import time\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gym_TicTacToe\n",
    "\n",
    "from src.qagent import QLearningAgent\n",
    "from src.play_tictactoe import play_tictactoe, play_tictactoe_with_random\n",
    "\n",
    "from src.utils import (\n",
    "    create_state_dictionary,\n",
    "    reshape_state,\n",
    "    save_qtable,\n",
    "    load_qtable\n",
    ")\n",
    "\n",
    "# ignore warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, color, episodes: int):\n",
    "        self.color = color\n",
    "        self.reward_array = np.zeros(episodes)\n",
    "        self.reset_reward()\n",
    "        self.name = f\"Player {color}\"\n",
    "\n",
    "    def reset_reward(self):\n",
    "        self.reward = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize the tictactoe environment\n",
    "env = gym.envs.make(\"TTT-v0\", small=-1, large=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of legal states: 12092\n"
     ]
    }
   ],
   "source": [
    "state_dict = create_state_dictionary()\n",
    "state_size = len(state_dict.keys())\n",
    "action_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training parameters\n",
    "episodes = 960_000\n",
    "max_steps = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_parameters = {\n",
    "    \"max_epsilon\": 1.0,\n",
    "    \"min_epsilon\": 0.0,\n",
    "    \"decay_rate\": 0.00001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qagent = QLearningAgent(exploration_parameters, state_size, action_size, learning_rate=0.1, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_potential_lose(state, color: int) -> bool:\n",
    "        \"\"\"check if after agent's move there is a lose position\n",
    "\n",
    "        Args:\n",
    "            color (int): of the player's enemy\n",
    "\n",
    "        Returns:\n",
    "            bool: indicating if this was a crucial move\n",
    "        \"\"\"\n",
    "        state_check = np.copy(state)\n",
    "        lose = False\n",
    "        col = np.array([1,2])\n",
    "        #enemy color\n",
    "        enemy_color = color\n",
    "        player_color = col[col != enemy_color][0]\n",
    "        state_check[state_check == player_color] = -1\n",
    "        state_check[state_check == enemy_color] = 1\n",
    "        state_check = state_check.reshape(3,3)\n",
    "        for ii in range(3):\n",
    "            if (\n",
    "                # check columns\n",
    "                np.sum(state_check[:, ii]) == 2\n",
    "                # check rows\n",
    "                or np.sum(state_check[ii, :]) == 2\n",
    "                # check diagonal\n",
    "                or np.sum([state_check[0, 0], state_check[1, 1], state_check[2, 2]])\n",
    "                == 2\n",
    "                or np.sum([state_check[0, 2], state_check[1, 1], state_check[2, 0]])\n",
    "                == 2\n",
    "            ):\n",
    "                lose = True\n",
    "                break\n",
    "        return lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = np.array([0,1,2,\n",
    "                  0,1,2,\n",
    "                  2,0,1])\n",
    "\n",
    "check_for_potential_lose(state, color=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(qagent:QLearningAgent, player_color, state: int, action_space: np.array, last_turn: bool) -> tuple:\n",
    "    action = qagent.get_action(state, action_space)\n",
    "\n",
    "    # remove action from the action space\n",
    "    action_space = action_space[action_space != action]\n",
    "\n",
    "    new_state, reward, done, _ = env.step((action, player_color))\n",
    "\n",
    "    col = np.array([1,2])\n",
    "    # if done:\n",
    "    #     print(new)\n",
    "    #     reward -= 5\n",
    "    if (done == False):\n",
    "        if check_for_potential_lose(new_state, col[col != player_color][0]):\n",
    "            reward -= 7\n",
    "\n",
    "    # if (last_turn == True) and (done == False):\n",
    "    #     reward += 3    # Reward for draw\n",
    "\n",
    "    # elif (last_turn == True) and (done == True):\n",
    "    #     reward += 10\n",
    "        # print(f\"New_state:{new_state}, Reward:{reward}, Done:{done}\")\n",
    "    #TODO: maybe should change a marker after this agent turn \n",
    "    new_state = np.append(new_state, player_color)\n",
    "    new_state = state_dict[reshape_state(new_state)] \n",
    "\n",
    "    qagent.qtable[state, action] = qagent.update_qtable(\n",
    "        state, new_state, action, reward, state_dict\n",
    "    )\n",
    "    # new state\n",
    "    state = new_state\n",
    "    return state, action_space, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_random(qagent:QLearningAgent, player_color, state: int, action_space: np.array) -> tuple:\n",
    "    action = np.random.choice(action_space)\n",
    "    action_space = action_space[action_space != action]\n",
    "    new_state, reward, done, _ = env.step((action, player_color))\n",
    "    new_state = np.append(new_state, player_color)\n",
    "    new_state = state_dict[reshape_state(new_state)]\n",
    "    state = new_state\n",
    "    return state, action_space, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited_states = np.zeros((state_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lear_rate = 0.8\n",
    "gamma = 0.9\n",
    "qagent = QLearningAgent(exploration_parameters, state_size, action_size, learning_rate=lear_rate, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/960000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 135/960000 [00:00<32:42, 489.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.32\n",
      "episode: 0,             epsilon: 1.0,             sum q-table: 32.8772405069821,             elapsed time [min]: 0.0,              done [%]: 0.0             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 25181/960000 [00:42<25:58, 599.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.56\n",
      "episode: 25000,             epsilon: 0.78,             sum q-table: 10053.245437175632,             elapsed time [min]: 0.7,              done [%]: 2.604166666666667             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50142/960000 [01:20<24:08, 627.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.52\n",
      "episode: 50000,             epsilon: 0.61,             sum q-table: 24304.781875876615,             elapsed time [min]: 1.33,              done [%]: 5.208333333333334             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 75157/960000 [01:55<21:02, 700.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.52\n",
      "episode: 75000,             epsilon: 0.47,             sum q-table: 27630.54760220734,             elapsed time [min]: 1.93,              done [%]: 7.8125             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100094/960000 [02:29<20:46, 689.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.6\n",
      "episode: 100000,             epsilon: 0.37,             sum q-table: 28593.042713084873,             elapsed time [min]: 2.48,              done [%]: 10.416666666666668             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 125149/960000 [03:01<18:43, 743.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.6\n",
      "episode: 125000,             epsilon: 0.29,             sum q-table: 28895.677182157342,             elapsed time [min]: 3.01,              done [%]: 13.020833333333334             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 150143/960000 [03:32<17:24, 775.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.56\n",
      "episode: 150000,             epsilon: 0.22,             sum q-table: 28994.798990368774,             elapsed time [min]: 3.53,              done [%]: 15.625             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 175200/960000 [04:01<16:24, 797.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.64\n",
      "episode: 175000,             epsilon: 0.17,             sum q-table: 29038.99814879319,             elapsed time [min]: 4.03,              done [%]: 18.229166666666664             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 200199/960000 [04:31<15:25, 821.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.56\n",
      "episode: 200000,             epsilon: 0.14,             sum q-table: 29050.92567414544,             elapsed time [min]: 4.51,              done [%]: 20.833333333333336             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 225137/960000 [04:59<15:15, 802.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.52\n",
      "episode: 225000,             epsilon: 0.11,             sum q-table: 29055.029605458054,             elapsed time [min]: 4.99,              done [%]: 23.4375             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 250113/960000 [05:27<14:08, 836.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.72\n",
      "episode: 250000,             epsilon: 0.08,             sum q-table: 29058.250216776894,             elapsed time [min]: 5.46,              done [%]: 26.041666666666668             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 275209/960000 [05:55<13:39, 835.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.64\n",
      "episode: 275000,             epsilon: 0.06,             sum q-table: 29058.46418815173,             elapsed time [min]: 5.92,              done [%]: 28.645833333333332             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 300121/960000 [06:22<13:23, 821.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.8\n",
      "episode: 300000,             epsilon: 0.05,             sum q-table: 29058.558424565363,             elapsed time [min]: 6.38,              done [%]: 31.25             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 325136/960000 [06:50<12:02, 879.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.68\n",
      "episode: 325000,             epsilon: 0.04,             sum q-table: 29058.55846648893,             elapsed time [min]: 6.83,              done [%]: 33.85416666666667             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 350214/960000 [07:17<11:24, 891.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.68\n",
      "episode: 350000,             epsilon: 0.03,             sum q-table: 29058.559094734206,             elapsed time [min]: 7.29,              done [%]: 36.45833333333333             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 375261/960000 [07:46<10:35, 920.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.52\n",
      "episode: 375000,             epsilon: 0.02,             sum q-table: 29058.55909499938,             elapsed time [min]: 7.77,              done [%]: 39.0625             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 400136/960000 [08:15<13:51, 673.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.76\n",
      "episode: 400000,             epsilon: 0.02,             sum q-table: 29063.787855371997,             elapsed time [min]: 8.26,              done [%]: 41.66666666666667             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 425154/960000 [08:43<10:24, 857.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.6\n",
      "episode: 425000,             epsilon: 0.01,             sum q-table: 29063.787855371997,             elapsed time [min]: 8.73,              done [%]: 44.27083333333333             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 450201/960000 [09:10<09:35, 885.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.52\n",
      "episode: 450000,             epsilon: 0.01,             sum q-table: 29063.787855371997,             elapsed time [min]: 9.17,              done [%]: 46.875             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 475286/960000 [09:37<08:59, 898.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.6\n",
      "episode: 475000,             epsilon: 0.01,             sum q-table: 29063.787855371997,             elapsed time [min]: 9.62,              done [%]: 49.47916666666667             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 500127/960000 [10:04<09:13, 830.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.56\n",
      "episode: 500000,             epsilon: 0.01,             sum q-table: 29063.787855371997,             elapsed time [min]: 10.07,              done [%]: 52.083333333333336             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 525158/960000 [10:30<08:16, 876.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.8\n",
      "episode: 525000,             epsilon: 0.01,             sum q-table: 29063.787855371997,             elapsed time [min]: 10.51,              done [%]: 54.6875             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 550283/960000 [10:57<07:22, 926.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.6\n",
      "episode: 550000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 10.95,              done [%]: 57.291666666666664             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 575235/960000 [11:24<07:16, 880.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.56\n",
      "episode: 575000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 11.4,              done [%]: 59.895833333333336             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 600260/960000 [11:50<06:49, 877.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.56\n",
      "episode: 600000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 11.84,              done [%]: 62.5             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 625219/960000 [12:17<06:09, 904.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.32\n",
      "episode: 625000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 12.29,              done [%]: 65.10416666666666             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 650133/960000 [12:43<05:50, 884.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.76\n",
      "episode: 650000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 12.73,              done [%]: 67.70833333333334             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 675185/960000 [13:10<05:23, 880.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.72\n",
      "episode: 675000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 13.16,              done [%]: 70.3125             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 700247/960000 [13:37<05:04, 853.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.84\n",
      "episode: 700000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 13.61,              done [%]: 72.91666666666666             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 725239/960000 [14:00<03:36, 1083.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.6\n",
      "episode: 725000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 14.0,              done [%]: 75.52083333333334             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 750201/960000 [14:23<03:24, 1027.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.64\n",
      "episode: 750000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 14.39,              done [%]: 78.125             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 775287/960000 [14:46<02:57, 1040.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.6\n",
      "episode: 775000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 14.77,              done [%]: 80.72916666666666             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 800221/960000 [15:09<02:35, 1027.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.68\n",
      "episode: 800000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 15.15,              done [%]: 83.33333333333334             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 825268/960000 [15:32<02:05, 1076.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.52\n",
      "episode: 825000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 15.53,              done [%]: 85.9375             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 850217/960000 [15:55<01:47, 1018.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.68\n",
      "episode: 850000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 15.91,              done [%]: 88.54166666666666             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 875270/960000 [16:17<01:21, 1037.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.68\n",
      "episode: 875000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 16.3,              done [%]: 91.14583333333334             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 900231/960000 [16:40<00:56, 1050.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.32\n",
      "episode: 900000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 16.67,              done [%]: 93.75             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 925255/960000 [17:03<00:32, 1072.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.76\n",
      "episode: 925000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 17.05,              done [%]: 96.35416666666666             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 950328/960000 [17:26<00:09, 1067.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.56\n",
      "episode: 950000,             epsilon: 0.0,             sum q-table: 29063.787855371997,             elapsed time [min]: 17.43,              done [%]: 98.95833333333334             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 960000/960000 [17:35<00:00, 909.92it/s] \n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "player_1 = Player(color=1, episodes=episodes)\n",
    "player_2 = Player(color=2, episodes=episodes)\n",
    "\n",
    "win_history = []\n",
    "\n",
    "rewards = []\n",
    "# lr = 0.4, gamma = 0.9, winrate = 0.64\n",
    "# Learning rate: 0.5, Win rate: 0.72, Gamma: 0.9\n",
    "# Learning rate: 0.6, Win rate: 0.5, Gamma: 0.9\n",
    "# Learning rate: 0.7, Win rate: 0.66, Gamma: 0.9\n",
    "# Learning rate: 0.65, Win rate: 0.76, Gamma: 0.8\n",
    "\n",
    "# best \n",
    "# Learning rate: 0.8, Win rate: 0.8, Gamma: 0.9\n",
    "\n",
    "# qagent_old = qagent\n",
    "for episode in tqdm(range(episodes)):\n",
    "    last_turn = False\n",
    "    action_space = np.arange(9)\n",
    "    player_1.reset_reward()\n",
    "    player_2.reset_reward()\n",
    "\n",
    "    # randomly change the order players\n",
    "    start = np.random.choice([1,2])\n",
    "\n",
    "    state, _ = env.reset()\n",
    "    state = np.append(state, start)\n",
    "    state = state_dict[reshape_state(state)]\n",
    "    # if episode % 10_000 == 0:\n",
    "    #     save_qtable(qagent.qtable, 'tables', \"q_table_old\")\n",
    "\n",
    "    for _step in range(start, max_steps + start):\n",
    "        if _step == max_steps + start - 1:\n",
    "            last_turn = True\n",
    "        # change a turn\n",
    "        if _step % 2 == 0:\n",
    "            #state, action_space, done = play_random(qagent, player_1.color, state, action_space)\n",
    "            #qagent_old.qtable = load_qtable('tables', \"q_table_old\")\n",
    "            state, action_space, done = play(qagent, player_1.color, state, action_space, last_turn)\n",
    "        else:\n",
    "            state, action_space, done = play(qagent, player_2.color, state, action_space, last_turn)\n",
    "        visited_states[state] += 1\n",
    "        if done == True:\n",
    "            break\n",
    "\n",
    "    # reduce epsilon for exporation-exploitation tradeoff\n",
    "    qagent.update_epsilon(episode)\n",
    "\n",
    "    #cur_win_rate, reward = play_tictactoe_with_random(env, qagent.qtable, state_dict, num_test_games=100)\n",
    "\n",
    "    #check how good is agent\n",
    "    if episode % 25_000 == 0:\n",
    "        num_games = 50\n",
    "        cur_win_rate, reward = play_tictactoe_with_random(env, qagent.qtable, state_dict, num_test_games=num_games)\n",
    "        win_history.append(sum(cur_win_rate)/num_games)\n",
    "        print(\"WinRate:\", sum(cur_win_rate)/num_games)\n",
    "        # rewards.append(reward)\n",
    "        # clear_output(True)\n",
    "        # # plt.title('eps = {:e}, mean reward = {:.1f}'.format(agent.epsilon, np.mean(rewards[-10:])))\n",
    "        # plt.plot(rewards)\n",
    "        # plt.show()\n",
    "    if episode % 25_000 == 0:\n",
    "\n",
    "        sum_q_table = np.sum(qagent.qtable)\n",
    "        time_passed = round((time.time() - start_time) / 60.0, 2)\n",
    "\n",
    "        print(\n",
    "            f\"episode: {episode}, \\\n",
    "            epsilon: {round(qagent.epsilon, 2)}, \\\n",
    "            sum q-table: {sum_q_table}, \\\n",
    "            elapsed time [min]: {time_passed},  \\\n",
    "            done [%]: {episode / episodes * 100} \\\n",
    "            \"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: 90.58881905391995\n"
     ]
    }
   ],
   "source": [
    "visited_states.shape[0]\n",
    "print(\"Percent:\",100*np.sum(visited_states > 0)/visited_states.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WinRate: 0.57\n"
     ]
    }
   ],
   "source": [
    "num_games = 1000\n",
    "cur_win_rate, _ = play_tictactoe_with_random(env, qagent.qtable, state_dict, num_test_games=num_games)\n",
    "win_history.append(sum(cur_win_rate)/num_games)\n",
    "print(\"WinRate:\", sum(cur_win_rate)/num_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_table_best2.npy saved!\n"
     ]
    }
   ],
   "source": [
    "qtable = qagent.qtable\n",
    "save_qtable(qtable, 'tables', \"q_table_best2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtable = load_qtable('tables', \"q_table_best2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6220\n",
      "[[0 1 2]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      "Turn was: 1\n",
      "[[ 0.1  0.   0. ]\n",
      " [ 0.1  0.   0.1]\n",
      " [ 0.1 -1.   0.1]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#check how correct is q-table\n",
    "\n",
    "state = np.random.choice(np.arange(env.observation_space.n))\n",
    "# state_dict[state]\n",
    "print(state)\n",
    "\n",
    "key = list(filter(lambda x: state_dict[x] == state, state_dict))[0]\n",
    "print(np.array(key[:-1]).reshape(3,3))\n",
    "print(\"Turn was:\", key[-1])\n",
    "print(np.round(qagent.qtable[state].reshape(3,3),2))\n",
    "\n",
    "# q = np.round(qtable[state],2)\n",
    "# print(\"Action: \",np.argmax(q))\n",
    "\n",
    "state_pure = np.array(key[:-1])\n",
    "action_space = np.where(state_pure == 0)[0]\n",
    "\n",
    "best_action = max(action_space, key=lambda action: qagent.qtable[state, action])\n",
    "print(best_action)\n",
    "# array = np.array(qtable[state, :])\n",
    "# order = array.argsort()\n",
    "# ranks = order.argsort()\n",
    "# max_value_rank = np.min(ranks[action_space])\n",
    "# action = np.where(ranks == max_value_rank)[0][0]\n",
    "# action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent beginns\n",
      "--------------------\n",
      "╒═══╤═══╤═══╕\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 1\n",
      "╒═══╤═══╤═══╕\n",
      "│ - │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "\n",
      "\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 0\n",
      "╒═══╤═══╤═══╕\n",
      "│ X │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "-1\n",
      "\n",
      "\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 6\n",
      "╒═══╤═══╤═══╕\n",
      "│ X │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ - │\n",
      "├───┼───┼───┤\n",
      "│ O │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "\n",
      "\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 5\n",
      "╒═══╤═══╤═══╕\n",
      "│ X │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ - │ - │ X │\n",
      "├───┼───┼───┤\n",
      "│ O │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "-1\n",
      "\n",
      "\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 3\n",
      "╒═══╤═══╤═══╕\n",
      "│ X │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ O │ - │ X │\n",
      "├───┼───┼───┤\n",
      "│ O │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "\n",
      "\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 4\n",
      "╒═══╤═══╤═══╕\n",
      "│ X │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ O │ X │ X │\n",
      "├───┼───┼───┤\n",
      "│ O │ - │ - │\n",
      "╘═══╧═══╧═══╛\n",
      "-1\n",
      "\n",
      "\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 8\n",
      "╒═══╤═══╤═══╕\n",
      "│ X │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ O │ X │ X │\n",
      "├───┼───┼───┤\n",
      "│ O │ - │ O │\n",
      "╘═══╧═══╧═══╛\n",
      "\n",
      "\n",
      "--------------------\n",
      "Move Human\n",
      "Action: 7\n",
      "╒═══╤═══╤═══╕\n",
      "│ X │ O │ - │\n",
      "├───┼───┼───┤\n",
      "│ O │ X │ X │\n",
      "├───┼───┼───┤\n",
      "│ O │ X │ O │\n",
      "╘═══╧═══╧═══╛\n",
      "-1\n",
      "\n",
      "\n",
      "--------------------\n",
      "move Agent\n",
      "Action: 2\n",
      "╒═══╤═══╤═══╕\n",
      "│ X │ O │ O │\n",
      "├───┼───┼───┤\n",
      "│ O │ X │ X │\n",
      "├───┼───┼───┤\n",
      "│ O │ X │ O │\n",
      "╘═══╧═══╧═══╛\n",
      "\n",
      "\n",
      "There is no Winner!\n",
      "--------------------\n",
      "--------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "play_tictactoe(env, qtable, state_dict, num_test_games=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6050d35557e2eda2bee3489ac5b9239cf3ea28e67ca6bb3b65a2efaf99506245"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tictactoe_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
